version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    hostname: zookeeper
    container_name: zookeeper
    ports:
     - "2181:2181"
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    hostname: kafka
    container_name: kafka
    links: 
      - zookeeper
    environment:
      - KAFKA_ADVERTISED_HOST=kafka 
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_PORT=9092
    volumes:
      - ./kafka_script/:/scripts
      - /var/run/docker.sock:/var/run/docker.sock
  namenode:
    image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
    container_name: namenode
    volumes:
      - ./data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - ./hadoop.env
    ports:
      - 50070:50070
  datanode:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    container_name: datanode
    depends_on: 
      - namenode
    volumes:
      - ./data/datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075
  spark-master:
    image: rosafilgueira/spark.2.2.0:latest 
    container_name: spark-master
    environment:
      - MASTER=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=192.171.148.207
      - SPARK_DRIVER_MEMORY=2g
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_MASTER_OPTS="-Dspark.driver.port=7021"
    expose:
      - 7021
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 7021:7021
      - 4040:4040
      - 8080:8080
      - 7077:7077
      - 6066:6066
    volumes:
      - ./conf/master:/conf
      - ./pyspark_app:/app/
      - ./pyspark_app/dependencies:/app_dependencies
      - ./pyspark_app/submit_scripts/:/submit_scripts
      - ./pyspark_app/data:/data
    command: bin/spark-class org.apache.spark.deploy.master.Master -h spark-master
    links:
      - kafka
      - elasticsearch
  spark-worker:
    image: rosafilgueira/spark.2.2.0:latest 
    hostname: spark-worker
    container_name: spark-worker
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_PORT=8881
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_EXECUTOR_INSTANCES=1
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_PUBLIC_DNS=192.171.148.207
      - SPARK_DRIVER_MEMORY=2g
    links:
      - spark-master
      - kafka
      - elasticsearch
    depends_on:
      - spark-master
      - kafka
      - elasticsearch
    expose:
      - 7011
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 7011:7011
      - 8081:8081
    volumes:
      - ./conf/worker:/conf
      - ./pyspark_app/tmp:/test_output
      - ./pyspark_app/data:/data
      - ./pyspark_app/scripts:/scripts
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  notebook:
    image: jupyter/pyspark-notebook
    hostname: jupyter
    container_name: spark-notebook
    depends_on:
      - spark-master
      - kafka
    links:
      - spark-master
      - kafka
    environment:
      - SPARK_OPTS='--master=spark://spark-master:7077'
    ports:
      - "8888:8888"
    volumes:
      - ./spark:/home/jovyan/work
      - ./mydata:/home/jovyan/work/data
    command: "start-notebook.sh --NotebookApp.token=''"

  
  elasticsearch:
    build: docker-elasticsearch/
    container_name: elasticsearch
    environment:
      - Des.network.host=0.0.0.0
    expose:
      - 9200
    ports:
      - "9200:9200"

